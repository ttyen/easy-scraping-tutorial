{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup 基本用法\n",
    "## Beautiful Soup 的運作方式就是讀取 HTML 原始碼，自動進行解析並產生一個 BeautifulSoup 物件，此物件中包含了整個 HTML 文件的結構樹，有了這個結構樹之後，就可以輕鬆找出任何有興趣的資料了。\n",
    "## https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入 Beautiful Soup 模組\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 原始 HTML 程式碼\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>Hello World</title></head>\n",
    "<body><h2>Test Header</h2>\n",
    "<p>This is a test.</p>\n",
    "<a id=\"link1\" href=\"/my_link1\">Link 1</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link 2</a>\n",
    "<p>Hello, <b class=\"boldtext\">Bold Text</b></p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# 以 Beautiful Soup 解析 HTML 程式碼\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先我們可以將完整個 HTML 結構經過排版後輸出，觀察整份文件的輪廓："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Hello World\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h2>\n",
      "   Test Header\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a test.\n",
      "  </p>\n",
      "  <a href=\"/my_link1\" id=\"link1\">\n",
      "   Link 1\n",
      "  </a>\n",
      "  <a href=\"/my_link2\" id=\"link2\">\n",
      "   Link 2\n",
      "  </a>\n",
      "  <p>\n",
      "   Hello,\n",
      "   <b class=\"boldtext\">\n",
      "    Bold Text\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 輸出排版後的 HTML 程式碼\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得節點文字內容\n",
    "## 若要輸出網頁標題的 HTML 標籤，可以直接指定網頁標題標籤的名稱（title），即可將該標籤的節點抓出來："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Hello World</title>\n"
     ]
    }
   ],
   "source": [
    "# 網頁標題 HTML 標籤\n",
    "title_tag = soup.title\n",
    "print(title_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML 標籤節點的文字內容，可以透過 string 屬性存取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# 網頁的標題文字\n",
    "print(title_tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搜尋節點\n",
    "## 我們可以使用 find_all 找出所有特定的 HTML 標籤節點，再以 Python 的迴圈來依序輸出每個超連結的文字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1\n",
      "Link 2\n"
     ]
    }
   ],
   "source": [
    "# 所有的超連結\n",
    "a_tags = soup.find_all('a')\n",
    "for tag in a_tags:\n",
    "  # 輸出超連結的文字\n",
    "  print(tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取出節點屬性\n",
    "## 若要取出 HTML 節點的各種屬性，可以使用 get，例如輸出每個超連結的網址（href 屬性）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/my_link1\n",
      "/my_link2\n"
     ]
    }
   ],
   "source": [
    "for tag in a_tags:\n",
    "  # 輸出超連結網址\n",
    "  print(tag.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同時搜尋多種標籤\n",
    "## 若要同時搜尋多種 HTML 標籤，可以使用 list 來指定所有的要列出的 HTML 標籤名稱："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>, <b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋所有超連結與粗體字\n",
    "tags = soup.find_all([\"a\", \"b\"])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 限制搜尋節點數量\n",
    "## find_all 預設會輸出所有符合條件的節點，但若是遇到節點數量很多的時候，就會需要比較久的計算時間，如果我們不需要所有符合條件的節點，可以用 limit 參數指定搜尋節點數量的上限值，這樣它就只會找出前幾個符合條件的節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>]\n"
     ]
    }
   ],
   "source": [
    "# 限制搜尋結果數量\n",
    "tags = soup.find_all([\"a\", \"b\"], limit=2)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果只需要抓出第一個符合條件的節點，可以直接使用 find："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/my_link1\" id=\"link1\">Link 1</a>\n"
     ]
    }
   ],
   "source": [
    "# 只抓出第一個符合條件的節點\n",
    "a_tag = soup.find(\"a\")\n",
    "print(a_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遞迴搜尋\n",
    "## 預設的狀況下，find_all 會以遞迴的方式尋找所有的子節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>Hello World</title>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 預設會以遞迴搜尋\n",
    "soup.html.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果想要限制 find_all 只找尋次一層的子節點，可以加上 recursive=False 關閉遞迴搜尋功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不使用遞迴搜尋，僅尋找次一層的子節點\n",
    "soup.html.find_all(\"title\", recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以 HTML 屬性搜尋\n",
    "## 我們也可以根據網頁 HTML 元素的屬性來萃取指定的 HTML 節點，例如搜尋 id 屬性為 link2 的節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/my_link2\" id=\"link2\">Link 2</a>\n"
     ]
    }
   ],
   "source": [
    "# 根據 id 搜尋\n",
    "link2_tag = soup.find(id='link2')\n",
    "print(link2_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我們可以結合 HTML 節點的名稱與屬性進行更精確的搜尋，例如搜尋 href 屬性為 /my_link1 的 a 節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋 href 屬性為 /my_link1 的 a 節點\n",
    "a_tag = soup.find_all(\"a\", href=\"/my_link1\")\n",
    "print(a_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜尋屬性時，也可以使用正規表示法，例如以正規表示法比對超連結網址："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 以正規表示法比對超連結網址\n",
    "links = soup.find_all(href=re.compile(\"^/my_link\\d\"))\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 我們也可以同時使用多個屬性的條件進行篩選："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 以多個屬性條件來篩選\n",
    "link = soup.find_all(href=re.compile(\"^/my_link\\d\"), id=\"link1\")\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 HTML5 中有一些屬性名稱若直接寫在 Python 的參數中會有一些問題，例如 data-* 這類的屬性直接寫的話，就會產生錯誤訊息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>', 'html.parser')\n",
    "\n",
    "# 錯誤的用法\n",
    "# data_soup.find_all(data-foo=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遇到這種狀況，可以把屬性的名稱與值放進一個 dictionary 中，再將此 dictionary 指定給 attrs 參數即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div data-foo=\"value\">foo!</div>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正確的用法\n",
    "data_soup.find_all(attrs={\"data-foo\": \"value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以 CSS 搜尋\n",
    "## 由於 class 是 Python 程式語言的保留字，所以 Beautiful Soup 改以 class_ 這個名稱代表 HTML 節點的 class 屬性，例如搜尋 class 為 boldtext 的 b 節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋 class 為 boldtext 的 b 節點\n",
    "b_tag = soup.find_all(\"b\", class_=\"boldtext\")\n",
    "print(b_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS 的 class 屬性也可以使用正規表示法搜尋："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 以正規表示法搜尋 class 屬性\n",
    "b_tag = soup.find_all(class_=re.compile(\"^bold\"))\n",
    "print(b_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一個 HTML 標籤元素可以同時有多個 CSS 的 class 屬性值，而我們在以 class_ 比對時，只要其中一個 class 符合就算比對成功，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'html.parser')\n",
    "\n",
    "# 只要其中一個 class 符合就算比對成功\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"strikeout\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我們也可以拿完整的 class 字串來進行比對："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "# 比對完整的 class 字串\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"body strikeout\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不過如果多個 class 名稱排列順序不同時，就會失敗："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 若順序不同，則會失敗\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"strikeout body\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遇到多個 CSS class 的狀況，建議改用 CSS 選擇器來篩選："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "# 使用 CSS 選擇器\n",
    "p_tag = css_soup.select(\"p.strikeout.body\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以文字內容搜尋\n",
    "## 若要依據文字內容來搜尋特定的節點，可以使用 find_all 配合 string 參數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/my_link1\" id=\"link1\">Link One</a>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_html = \"\"\"\n",
    "<a id=\"link1\" href=\"/my_link1\">Link One</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link Two</a>\n",
    "<a id=\"link3\" href=\"/my_link3\">Link Three</a>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(links_html, 'html.parser')\n",
    "\n",
    "# 搜尋文字為「Link One」的超連結\n",
    "soup.find_all(\"a\", string=\"Link One\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 亦可使用正規表示法批配文字內容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/my_link1\" id=\"link1\">Link One</a>,\n",
       " <a href=\"/my_link2\" id=\"link2\">Link Two</a>,\n",
       " <a href=\"/my_link3\" id=\"link3\">Link Three</a>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以正規表示法搜尋文字為「Link」開頭的超連結\n",
    "soup.find_all(\"a\", string=re.compile(\"^Link\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向上、向前與向後搜尋\n",
    "## 前面介紹的 find_all 都是向下搜尋子節點，如果需要向上搜尋父節點的話，可以改用 find_parents 函數（或是 find_parent），它可讓我們以某個特定節點為起始點，向上搜尋父節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"my_par\">\n",
      "<a href=\"/my_link1\" id=\"link1\">Link 1</a>\n",
      "<a href=\"/my_link2\" id=\"link2\">Link 2</a>\n",
      "<a href=\"/my_link3\" id=\"link3\">Link 3</a>\n",
      "<a href=\"/my_link4\" id=\"link3\">Link 4</a>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<body><p class=\"my_par\">\n",
    "<a id=\"link1\" href=\"/my_link1\">Link 1</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link 2</a>\n",
    "<a id=\"link3\" href=\"/my_link3\">Link 3</a>\n",
    "<a id=\"link3\" href=\"/my_link4\">Link 4</a>\n",
    "</p></body>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "link2_tag = soup.find(id=\"link2\")\n",
    "\n",
    "# 往上層尋找 p 節點\n",
    "p_tag = link2_tag.find_parents(\"p\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 如果想要在在同一層往前尋找特定節點，則可用 find_previous_siblings 函數（或是 find_previous_sibling）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 在同一層往前尋找 a 節點\n",
    "link_tag = link2_tag.find_previous_siblings(\"a\")\n",
    "print(link_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果想要在在同一層往後尋找特定節點，則可用 find_next_siblings 函數（或是 find_next_sibling）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link3\" id=\"link3\">Link 3</a>, <a href=\"/my_link4\" id=\"link3\">Link 4</a>]\n"
     ]
    }
   ],
   "source": [
    "# 在同一層往後尋找 a 節點\n",
    "link_tag = link2_tag.find_next_siblings(\"a\")\n",
    "print(link_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 網頁檔案\n",
    "## 如果我們想要用 Beautiful Soup 解析已經下載的 HTML 檔案，可以直接將開啟的檔案交給 BeautifulSoup 處理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下載 Yahoo 頭條新聞\n",
    "## Beautiful Soup 本身只是一個 HTML 解析工具，它並不負責下載網頁，所以通常我們在開發爬蟲程式時，會搭配 requests 模組一同使用。\n",
    "## 在這個範例中，我們打算開發一個爬蟲程式，可從 Yahoo 的首頁把頭條新聞的標題與網址抓下來，在開發程式之前，我們通常都會先用瀏覽器的開發人員工具，觀察一下目標網頁的 HTML 結構，找出我們有興趣的資料所在位置，並設計好萃取資料的規則。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以 Yahoo 頭條新聞來說，我們可以發現網頁中的頭條新聞超連結都有 story-title 這個 CSS 的 class，所以我們只要找出網頁中所有符合此條件的標籤，就可以把頭條新聞的資訊抓出來了。\n",
    "\n",
    "## 以下是使用 requests 模組從 Yahoo 下載首頁的 HTML 資料後，以 Beautiful Soup 翠取出頭條新聞標題的指令稿："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：「護妻心切」金正恩霸氣推開他\n",
      "網址：https://tw.news.yahoo.com/%E4%B8%8D%E6%BB%BF%E6%9D%8E%E9%9B%AA%E4%B8%BB%E8%A2%AB%E6%93%8B%E8%B7%AF-%E9%87%91%E6%AD%A3%E6%81%A9%E6%8E%A8%E9%96%8B%E6%94%9D%E5%BD%B1%E5%B8%AB-%E7%B6%B2%E8%AE%9A-%E7%9C%9F%E7%94%B7%E4%BA%BA-092655320.html\n",
      "標題：「1間接著1間關」老客戶痛心\n",
      "網址：https://tw.news.yahoo.com/%E6%98%8E%E5%84%806%E6%9C%88%E7%86%84%E7%87%88-%E9%82%A3%E4%BA%9B%E5%B9%B4-%E9%96%93%E9%96%93%E6%94%B6%E6%94%A4%E7%9A%84%E6%9B%B8%E5%BA%97-045819154.html\n",
      "標題：孫越遺照流出 家屬嗆告殯葬業者\n",
      "網址：https://tw.news.yahoo.com/%E5%AD%AB%E8%B6%8A%E9%81%BA%E7%85%A7%E6%B5%81%E5%87%BA%E5%82%B3%E5%AE%B6%E5%B1%AC%E9%9C%87%E6%80%92-%E4%BB%81%E6%9C%AC%E5%9B%9E%E6%87%89-%E9%80%99%E5%BC%B5%E7%85%A7%E7%89%87%E6%98%AF%E6%84%8F%E5%A4%96-091551517.html\n",
      "標題：挖到千年錢窖 驚見200公斤錢幣\n",
      "網址：https://tw.news.yahoo.com/%E7%99%BC%E4%BA%86-%E5%B7%A5%E5%9C%B0%E6%8C%96%E5%88%B0%E5%8D%83%E5%B9%B4%E9%8C%A2%E7%AA%96-200%E5%85%AC%E6%96%A4%E6%9D%B1%E6%BC%A2%E5%8F%A4%E5%B9%A3%E5%87%BA%E5%9C%9F-115841970.html\n",
      "標題：8強賽開打前 南北韓竟宣布併隊\n",
      "網址：https://tw.news.yahoo.com/%E4%B8%96%E9%8C%A6%E8%B3%BD%E6%89%93%E5%88%B08%E5%BC%B7-%E5%8D%97%E5%8C%97%E9%9F%93%E7%AB%9F%E7%9B%B4%E6%8E%A5%E4%BD%B5%E9%9A%8A-124806559.html\n",
      "標題：殷仔旅美生涯 首次對決他們\n",
      "網址：https://tw.news.yahoo.com/mlb-%E9%99%B3%E5%81%89%E6%AE%B7%E9%A6%96%E6%88%B0%E7%B4%85%E4%BA%BA-%E7%94%9F%E6%B6%AF%E7%AC%AC28%E5%80%8B%E5%B0%8D%E6%89%8B%E6%88%B0%E7%B8%BE%E7%88%9B-084231172.html\n",
      "標題：別人罰球他來亂！梁子結大了\n",
      "網址：https://tw.sports.yahoo.com/news/nba-%E6%9C%83%E7%AC%91%E6%AD%BB-%E5%8B%87%E5%A3%AB%E6%A0%BC%E6%9E%97%E7%BD%B0%E7%90%83%E9%B5%9C%E9%B6%98%E6%9C%97%E5%A4%9A-%E6%97%81%E6%83%A1%E6%90%9E-084231050.html\n",
      "標題：「五成鹿」？淘汰後困境才開始\n",
      "網址：https://tw.sports.yahoo.com/news/%E6%AF%94%E6%B7%98%E6%B1%B0%E6%9B%B4%E8%89%B1%E9%9B%A3%E7%9A%84%E8%99%95%E5%A2%83-%E7%95%B6%E9%80%99%E4%BA%9B%E7%90%83%E9%9A%8A%E5%AD%A3%E5%BE%8C%E8%B3%BD%E5%87%BA%E5%B1%80%E5%BE%8C-%E6%9D%B1%E5%8D%80%E7%AF%87-033826295.html\n",
      "標題：嫁對人！他買上億豪宅送岳母\n",
      "網址：https://tw.news.yahoo.com/%E5%A5%B3%E6%98%9F%E7%94%9F2%E5%8D%83%E9%87%91-%E5%AF%8C%E5%B0%AA%E9%80%81%E4%B8%88%E6%AF%8D%E5%A8%98%E8%B1%AA%E5%AE%85%E8%87%B4%E8%AC%9D-121546081.html\n",
      "標題：星二代歎「像被圍觀的動物」\n",
      "網址：https://tw.news.yahoo.com/%E6%98%9F%E4%BA%8C%E4%BB%A3%E5%8F%97%E7%9F%9A%E7%9B%AE-%E5%A5%B9%E5%98%86-%E5%83%8F%E8%A2%AB%E5%9C%8D%E8%A7%80%E7%9A%84%E5%8B%95%E7%89%A9-103113360.html\n",
      "標題：追夢艱辛 她曾靠兼3份工苦撐\n",
      "網址：https://tw.news.yahoo.com/%E5%AF%A6%E5%8A%9B%E6%AD%8C%E6%89%8Bheize%E9%9D%A0%E4%B8%89%E4%BB%BD%E5%B7%A5%E9%81%8E%E6%B4%BB-%E5%80%8B%E8%B6%85%E5%95%86%E4%BE%BF%E7%95%B6%E6%8A%B5%E4%B8%89%E9%A4%90-105448166.html\n",
      "標題：遭爆夜會男星 她公司說話了\n",
      "網址：https://tw.news.yahoo.com/%E7%88%86%E8%88%87%E7%94%B7%E6%98%9F%E7%A5%95%E6%88%80-%E5%B9%B4-%E7%B0%A1%E5%BB%B7%E8%8A%AE%E5%85%AC%E5%8F%B8%E7%99%BC%E8%81%B2%E6%98%8E-084605186.html\n",
      "標題：「喝完就上路」這罐附吸管傻了\n",
      "網址：https://tw.news.yahoo.com/%E5%9A%87-%E5%A5%B3%E5%AD%90%E8%B2%B7%E9%B9%BD%E9%85%B8%E5%BA%97%E5%93%A1%E7%B5%A6%E5%90%B8%E7%AE%A1-%E5%8E%9F%E5%9B%A0%E5%87%BA%E5%9C%A8-%E5%8C%85%E8%A3%9D-060743826.html#0503ac\n",
      "標題：情侶公開親熱 褲襠1亮點笑歪\n",
      "網址：https://tw.news.yahoo.com/%E5%B0%8F%E6%83%85%E4%BE%B6%E6%8D%B7%E9%81%8B%E4%B8%8A%E8%A6%AA%E7%86%B1-%E7%94%B7%E5%AD%A9%E5%AD%90%E8%BA%AB%E9%AB%94%E8%B6%85%E8%AA%A0%E5%AF%A6-%E7%B6%B2-%E9%80%99%E5%8F%AB%E8%B5%B7%E5%BA%8A%E6%B0%A3-030101374.html#0503ac\n",
      "標題：嚇瘋！熱銷蛋糕竟吃到人的…\n",
      "網址：https://yahoo.wakool.net/game/info/2000000173#0503ac\n",
      "標題：最潮玩法？全體狂推1照囧爆\n",
      "網址：http://bit.ly/2IdV9td\n",
      "標題：4月國產銷售榜 小黑馬衝第2\n",
      "網址：https://autos.yahoo.com.tw/news/2018%E5%B9%B4%E5%9B%9B%E6%9C%88%E4%BB%BD%E8%87%BA%E7%81%A3%E6%B1%BD%E8%BB%8A%E5%B8%82%E5%A0%B4%E9%8A%B7%E5%94%AE%E5%A0%B1%E5%91%8A-160900217.html#0503gu\n",
      "標題：是你該走嗎…老鳥1原因怒離了\n",
      "網址：https://tw.news.yahoo.com/%E3%80%90yahoo%E8%AB%96%E5%A3%87%EF%BC%8F%E9%BB%83%E5%A4%A7%E7%B1%B3%E3%80%91%E5%AE%B3%E8%80%81%E9%B3%A5%E5%A4%A9%E5%A4%A9%E5%8A%A0%E7%8F%AD%E3%80%81%E9%96%83%E9%9B%BB%E9%9B%A2%E8%81%B7-%E8%A6%81-010010411.html#0503gu\n",
      "標題：街景全狗屎垃圾？她嚇喊4字\n",
      "網址：https://tw.news.yahoo.com/%E7%8B%97%E5%B1%8E%E5%9E%83%E5%9C%BE%E6%88%90%E5%BF%85%E5%82%99%E8%A1%97%E6%99%AF-%E5%9C%A8%E4%B8%AD%E5%92%8C%E7%A7%9F%E5%B1%8B%E7%9A%84%E5%A5%B9%E5%9A%87%E5%82%BB-%E6%A0%B9%E6%9C%AC%E5%9C%B0%E7%8D%84-100008234.html#0503gu\n",
      "標題：4種魚少吃！汞中毒傷害大腦\n",
      "網址：http://bit.ly/2JQJopY\n",
      "標題：初戀再遇成上司 婚姻下場竟…\n",
      "網址：https://www.litv.tv/diversion/yahoo.do?content_id=VOD00111541&focus_time=187000&sponsorName=eWFob28=&autoPlay=1#0503ea\n",
      "標題：偷吃被抓包！二婚男驚冒1句\n",
      "網址：https://www.litv.tv/vod/show/content.do?brc_id=74&id=VOD00109719&sponsorName=eWFob28=&autoPlay=1#0503ea\n",
      "標題：純靠手技 18歲少女月收10萬\n",
      "網址：https://tw.tv.yahoo.com/yitiaotv/18%E6%AD%B2%E4%B8%8A%E6%B5%B7%E5%B0%91%E5%A5%B3%E9%9A%B1%E5%B1%85%E9%9B%B2%E5%8D%97%E6%B7%B1%E5%B1%B1%E9%96%8B%E7%B6%B2%E5%BA%97-135157189.html#0503ea\n",
      "標題：本土一哥獸行 下藥嫩妹逼…\n",
      "網址：https://tw.tv.yahoo.com/%E6%B5%81%E6%98%9F%E8%9D%B4%E8%9D%B6%E5%8A%8D-ep02-%E5%AE%8C%E6%95%B4%E7%89%88-051500471.html#0503ea\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 下載 Yahoo 首頁內容\n",
    "r = requests.get('https://tw.yahoo.com/')\n",
    "\n",
    "# 確認是否下載成功\n",
    "if r.status_code == requests.codes.ok:\n",
    "  # 以 BeautifulSoup 解析 HTML 程式碼\n",
    "  soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "  # 以 CSS 的 class 抓出各類頭條新聞\n",
    "  stories = soup.find_all('a', class_='story-title')\n",
    "  for s in stories:\n",
    "    # 新聞標題\n",
    "    print(\"標題：\" + s.text)\n",
    "    # 新聞網址\n",
    "    print(\"網址：\" + s.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下載 Google 搜尋結果\n",
    "## 這個範例我們要開發一個可以自動送出關鍵字到 Google 進行搜尋，並將搜尋結果抓回來的爬蟲程式，基本的開發概念都相同，只不過 Google 的網頁會因為瀏覽器（User-Agent）不同而產生不同的結果，所以在觀察程式碼的時候，最好是使用 Beautiful Soup 的 prettify 把抓回來的 HTML 原始碼排版後印出來，這樣看會比較準確。\n",
    "\n",
    "## Google 搜尋引擎網址是 https://www.google.com.tw/search，而關鍵字則是透過 q 這個參數送給它，這個規則只要稍微觀察一下瀏覽器所顯示的網址即可推論出來，有了這個規則之後，就可以用 requests 與 BeautifulSoup 先把 Google 搜尋結果的 HTML 原始碼抓下來看看。\n",
    "## 抓出 class 為 g 的 <div>，底下緊接著 class 為 r 的 <h3>，底下又接著網址為 /url 開頭的超連結。\n",
    "![](img/googlesearch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：寒流 - 中央氣象局\n",
      "網址：/url?q=https://www.cwb.gov.tw/V7/climate/climate_info/taiwan_climate/taiwan_3/taiwan_3_5.html&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggTMAA&usg=AOvVaw0BtBPr1yDRdVuGUKIqT8r0\n",
      "標題：寒流冷到週三氣象局：10日又有冷氣團報到- 生活- 自由時報電子報\n",
      "網址：/url?q=http://news.ltn.com.tw/news/life/breakingnews/2332229&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggYMAE&usg=AOvVaw1QXJydK46HlfMAPq1ZAFqN\n",
      "標題：彭啟明：清明連假後半段變冷但寒流不大可能| 生活新聞| 生活| 聯合 ...\n",
      "網址：/url?q=https://udn.com/news/story/7266/3060100&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggeMAI&usg=AOvVaw2oSNvLc3-vzit2bLCyiRkT\n",
      "標題：【冷不停】周末又有寒流來一路冷到下周二| 蘋果日報\n",
      "網址：/url?q=https://tw.appledaily.com/new/realtime/20180206/1292863/&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggkMAM&usg=AOvVaw3iC_sOM81lDkfjsbn9chh5\n",
      "標題：寒流- 維基百科，自由的百科全書 - Wikipedia\n",
      "網址：/url?q=https://zh.wikipedia.org/zh-tw/%25E5%25AF%2592%25E6%25B5%2581&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggqMAQ&usg=AOvVaw05p24TXbPfXlYeJc4zcxmx\n",
      "標題：寒流有多強？氣象局用一張圖說明- 中時電子報\n",
      "網址：/url?q=http://www.chinatimes.com/realtimenews/20180201003467-260405&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFggvMAU&usg=AOvVaw1fKjDcWtOJ4u5KQ0hf4lpB\n",
      "標題：下周每兩天變一次天專家：未來寒流機會少- 中時電子報\n",
      "網址：/url?q=http://www.chinatimes.com/realtimenews/20180223002575-260405&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFgg1MAY&usg=AOvVaw2oh_WgjP97CEc4uO7VbEZ8\n",
      "標題：寒流又要來了11至13日低溫探7度| 生活| 重點新聞| 中央社CNA\n",
      "網址：/url?q=http://www.cna.com.tw/news/firstnews/201802090028-1.aspx&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFgg7MAc&usg=AOvVaw0BFSWVKTjyMd48u4AJhTWY\n",
      "標題：天氣即時預報- 冷空氣解密：未來還有寒流嗎？ --... | Facebook\n",
      "網址：/url?q=https://www.facebook.com/weather.taiwan/posts/1630102397045512&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFghBMAg&usg=AOvVaw2QBnW568cJWnDmbipDpk4g\n",
      "標題：寒流進度3/5！專家：麻煩的是周日- Yahoo奇摩新聞\n",
      "網址：/url?q=https://tw.news.yahoo.com/%25E5%25AF%2592%25E6%25B5%2581%25E9%2580%25B2%25E5%25BA%25A63-5-%25E5%25B0%2588%25E5%25AE%25B6-%25E9%25BA%25BB%25E7%2585%25A9%25E7%259A%2584%25E6%2598%25AF%25E5%2591%25A8%25E6%2597%25A5-012910685.html&sa=U&ved=0ahUKEwiSh82dhOraAhXMnJQKHWp8BJsQFghDMAk&usg=AOvVaw1wbo2dvARCx07zShwVhsFP\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Google 搜尋 URL\n",
    "google_url = 'https://www.google.com.tw/search'\n",
    "\n",
    "# 查詢參數\n",
    "my_params = {'q': '寒流'}\n",
    "\n",
    "# 下載 Google 搜尋結果\n",
    "r = requests.get(google_url, params = my_params)\n",
    "\n",
    "# 確認是否下載成功\n",
    "if r.status_code == requests.codes.ok:\n",
    "  # 以 BeautifulSoup 解析 HTML 原始碼\n",
    "  soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "  # 觀察 HTML 原始碼\n",
    "  # print(soup.prettify())\n",
    "\n",
    "  # 以 CSS 的選擇器來抓取 Google 的搜尋結果\n",
    "  items = soup.select('div.g > h3.r > a[href^=\"/url\"]')\n",
    "  for i in items:\n",
    "    # 標題\n",
    "    print(\"標題：\" + i.text)\n",
    "    # 網址\n",
    "    print(\"網址：\" + i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
